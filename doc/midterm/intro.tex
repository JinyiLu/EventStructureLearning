\section{Introduction}
One of the classic problems of natural language processing (NLP) is the modeling of stereotypical event sequences in narratives, such as the stages of a terrorist attack or the event structure of a criminal conviction. Incorporating such abstract knowledge into the model can often significantly improve the quality and accuracy of many NLP tasks, like summarization and question answering. Traditionally, this has been modeled with the use of scripts \cite{SA77}, which encode knowledge of stereotypical events, including information about their typical ordered sequences of subevents and corresponding arguments (temporal, causal, relational, etc.). While this approach is both powerful and general, it requires very careful engineering and hand-compiling a large list of event scripts, making it difficult to scale to larger and more complex event structures.

Recently, there has been some work done on automatically learning models of scripts from large corpora of raw text \cite{B08, C13, CJ09schema, CJ08chain}. There are lots of challenges for this task, including how to model the various relationships between events, and how to maintain the contextual coherence in the scripts. Thus, all these works make many assumptions on the scripts to be learned---e.g. structures are restricted to be chains, structures are limited to frequent topics in a large corpus or redundant documents about specific events are required, sometimes the relations are binary, and often only slots with named entities are learned. Our goal in this project is to explore semi-supervised and unsupervised learning approaches for discovering events as well as the temporal relations involving events (and possibly time expressions). One idea is to extend Rel-graphs introduced by Balasubramanian et al. \cite{BSME13} to use directed arcs among tuples. Another possibility is to introduce temporal labels into the frame induction approach by Cheung, Poon, and Vanderwende \cite{CPV13} as the basis for a semi-supervised model. We expect our solution can find more reasonable event structures and require less/no labeled data. The techniques potentially involved include dependency parsing, coreference resolution, LDA, and others.

Due to the well-established nature of this problem, there are many datasets on which to train our model, including the MUC-4 dataset and the translation task dataset from statmt.org. Standard software used by for feature extraction is also available for download from Stanford NLP. We expect to have a preliminary solution which can nearly match the state-of-the-art methods in the midterm, and we will continue to improve our solution until the final.